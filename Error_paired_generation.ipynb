{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CT-RATE label csv 가져와서 id 매칭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ctrate\n",
    "ct_rate_df = pd.read_csv('/workspace/7.Error/csv/CTRATE_train_predicted_labels.csv')\n",
    "ct_rate_df = ct_rate_df[['VolumeName', 'Lung nodule', 'Pleural effusion']]\n",
    "\n",
    "# radgenome\n",
    "abnormal_df = pd.read_csv('/workspace/7.Error/csv/RADGENOME_train_vqa_abnormality.csv')\n",
    "abnormal_df = abnormal_df[abnormal_df['Anatomy'] == 'lung']\n",
    "\n",
    "# merge ctrate\n",
    "ct_rate_df = ct_rate_df.merge(abnormal_df, left_on='VolumeName', right_on='Volumename', how='left')\n",
    "ct_rate_df.drop(columns=['Volumename'], inplace=True)\n",
    "\n",
    "# radgenome\n",
    "train_df = pd.read_csv('/workspace/7.Error/csv/medregion_report_train.csv')\n",
    "valid_df = pd.read_csv('/workspace/7.Error/csv/medregion_report_valid.csv')\n",
    "data_df  = pd.concat([train_df, valid_df], axis=0)\n",
    "data_df  = data_df[['ct_path', 'id', 'full_report', 'lung_parenchyma']]\n",
    "\n",
    "# merge radgenome\n",
    "merged_df = data_df.merge(ct_rate_df, left_on='id', right_on='VolumeName', how='left')\n",
    "merged_df.drop(columns=['VolumeName'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodule_df = merged_df[(merged_df['Lung nodule'] == 1) \n",
    "                      & (merged_df['Pleural effusion'] == 0) \n",
    "                      & (merged_df['lung_parenchyma'].str.contains('nodule'))]\n",
    "\n",
    "effusion_df = merged_df[(merged_df['Lung nodule'] == 0) \n",
    "                        & (merged_df['Pleural effusion'] == 1) \n",
    "                        & (merged_df['lung_parenchyma'].str.contains('effusion'))]\n",
    "\n",
    "none_df = merged_df[(merged_df['Lung nodule'] == 0) \n",
    "                    & (merged_df['Pleural effusion'] == 0) \n",
    "                    & (merged_df['Abnormality'].str.lower()=='no findings')]\n",
    "\n",
    "len(nodule_df), len(effusion_df), len(none_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 체크\n",
    "\n",
    "print(set(nodule_df['id'].values) & set(none_df['id'].values))\n",
    "print(set(effusion_df['id'].values) & set(none_df['id'].values))\n",
    "print(set(nodule_df['id'].values) & set(effusion_df['id'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "nodule_sample_df   = nodule_df.sample(1000)\n",
    "effusion_sample_df = effusion_df.sample(1000)\n",
    "none_sample_df     = none_df.sample(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodule_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "\n",
    "nodule_sample_df.to_csv('/workspace/7.Error/csv/nodule_sample_1000.csv', index=False)\n",
    "effusion_sample_df.to_csv('/workspace/7.Error/csv/effusion_sample_1000.csv', index=False)\n",
    "none_sample_df.to_csv('/workspace/7.Error/csv/none_sample_1000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error generation using dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python code/error_generation_dspy.py --csv_path /workspace/7.Error/csv --save_path /workspace/7.Error/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dspy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Pair 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "none_sample_df     = pd.read_csv('/workspace/7.Error/csv/dspy_none_1000.csv')\n",
    "effusion_sample_df = pd.read_csv('/workspace/7.Error/csv/dspy_effusion_1000.csv')\n",
    "nodule_sample_df   = pd.read_csv('/workspace/7.Error/csv/dspy_nodule_1000.csv')\n",
    "\n",
    "omission_effusion   = effusion_sample_df[effusion_sample_df['omission_effusion_classification'] == 1]\n",
    "insertion_nodule    = effusion_sample_df[effusion_sample_df['insertion_nodule_classification'] == 1]\n",
    "direction_effusion  = effusion_sample_df[effusion_sample_df['direction_effusion_classification'] == 1]\n",
    "size_effusion       = effusion_sample_df[effusion_sample_df['size_classification'] == 1]\n",
    "typo_effusion       = effusion_sample_df[effusion_sample_df['typo_classification'] == 1]\n",
    "unit_effusion       = effusion_sample_df[effusion_sample_df['unit_classification'] == 1]\n",
    "\n",
    "omission_nodule    = nodule_sample_df[nodule_sample_df['omission_nodule_classification'] == 1]\n",
    "insertion_effusion = nodule_sample_df[nodule_sample_df['insertion_effusion_classification'] == 1]\n",
    "direction_nodule   = nodule_sample_df[nodule_sample_df['direction_nodule_classification'] == 1]\n",
    "size_nodule        = nodule_sample_df[nodule_sample_df['size_classification'] == 1]\n",
    "typo_nodule        = nodule_sample_df[nodule_sample_df['typo_classification'] == 1]\n",
    "unit_nodule        = nodule_sample_df[nodule_sample_df['unit_classification'] == 1]\n",
    "\n",
    "none_insert_nodule   = none_sample_df[none_sample_df['insertion_nodule_classification'] == 1]\n",
    "none_insert_effusion = none_sample_df[none_sample_df['insertion_effusion_classification'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_format = {\n",
    "    \"classification\": [\n",
    "        \"Evaluate the accuracy of the provided medical report based on the given CT scan image. Respond strictly with either 0 (report accurate) or 1 (report contains inaccuracies).\\nAnswer Format: '0' or '1'\",\n",
    "        \"Check the provided medical report for correctness using the CT scan image as a reference. Your response must strictly be either 0 (report is correct) or 1 (report is incorrect).\\nAnswer Format: '0' or '1'\",\n",
    "        \"Determine if the medical report accurately describes the provided CT scan. Answer strictly 0 if the report is correct, or 1 if it contains any errors.\\nAnswer Format: '0' or '1'\",\n",
    "        \"Assess the medical report for any errors or inaccuracies using the provided CT scan image as the standard reference. Return exactly 0 if no errors exist, or exactly 1 if errors are present.\\nAnswer Format: '0' or '1'\",\n",
    "        \"Verify whether the medical report is accurate based on the provided CT scan. Return strictly 0 for correct or 1 if any inaccuracies exist.\\nAnswer Format: '0' or '1'\"\n",
    "    ],    \n",
    "    \n",
    "    \"detection\": [\n",
    "        \"Identify and extract sentences from the provided medical report that contain inaccuracies or inconsistencies relative to the image. If none exist, reply: 'No errors detected.'\\nAnswer Format: '{error sentence}' or 'No errors detected.'\",\n",
    "        \"Detect report-image errors. Output erroneous sentence(s) or 'No errors detected.'\\nAnswer Format: '{error sentence}' or 'No errors detected.'\",\n",
    "        \"Check the medical report for any errors, including mismatches with the image. If any such issues are found, point out the exact sentence(s) involved. If everything is accurate and consistent, say: 'No errors detected.'\\nAnswer Format: '{error sentence}' or 'No errors detected.'\",\n",
    "        \"Scan the medical report for any errors or factual discrepancies in comparison to the image. Return erroneous sentence(s) or respond with 'No errors detected.'\\nAnswer Format: '{error sentence}' or 'No errors detected.'\",\n",
    "        \"Highlight any incorrect, mismatched, or erroneous sentences in the medical report, including those that conflict with the provided image. If no issues are found, respond clearly with 'No errors detected.'\\nAnswer Format: '{error sentence}' or 'No errors detected.'\"\n",
    "    ],   \n",
    "    \n",
    "    \"detection_index\": [\n",
    "        \"Identify and extract the index numbers of sentences in the provided medical report that contain inaccuracies or inconsistencies with reference to the image. If no errors are found, output '0' to indicate no issues.\\nAnswer Format: '{index}' or '0'\",\n",
    "        \"Detect report-image errors. Output the index of each erroneous sentence. If there are no errors, respond with '0' to indicate all sentences are correct.\\nAnswer Format: '{index}' or '0'\",\n",
    "        \"Check the medical report for any errors, including mismatches with the image. If any such issues are found, return the index numbers of the sentences involved. If everything is consistent, output '0' to indicate no errors.\\nAnswer Format: '{index}' or '0'\",\n",
    "        \"Scan the medical report for any errors or factual discrepancies in comparison to the image. Return the index numbers of any erroneous sentences. If no such sentences exist, respond with '0' to indicate no issues were detected.\\nAnswer Format: '{index}' or '0'\",\n",
    "        \"Highlight any incorrect, mismatched, or erroneous sentences in the medical report, including those that conflict with the provided image. If the report is fully accurate, clearly respond with '0' to show that no errors were found.\\nAnswer Format: '{index}' or '0'\"\n",
    "    ],    \n",
    "    \n",
    "    \"correction\": [\n",
    "        \"Review the medical report in comparison with the provided image. First, identify any sentence(s) that are inaccurate or any important findings from the image that are missing from the report. Then, provide a corrected version of the inaccurate sentence(s) or write the missing sentence(s) that should have been included. If no issues are found, respond: 'No errors detected.'\\nAnswer Format: '{corrected or added sentence}' or 'No errors detected.'\",\n",
    "        \"Compare the medical report with the corresponding image. First, identify any erroneous or omitted sentence(s) based on the image. Then, revise the incorrect sentence(s) or generate the sentence(s) that were missing. If the report is accurate and complete, respond: 'No errors detected.'\\nAnswer Format: '{corrected or added sentence}' or 'No errors detected.'\",\n",
    "        \"Analyze the medical report with reference to the provided image. First, detect any errors or missing descriptions. Then, return the corrected version of the inaccurate content or the missing sentence(s). If everything is accurate, respond with 'No errors detected.'\\nAnswer Format: '{corrected or added sentence}' or 'No errors detected.'\",\n",
    "        \"Evaluate the medical report with the given image. Begin by identifying any inaccurate or missing statement(s) in the report. After identifying them, present either the corrected version or the appropriate missing sentence(s). If no problems are found, respond: 'No errors detected.'\\nAnswer Format: '{corrected or added sentence}' or 'No errors detected.'\",\n",
    "        \"Examine the medical report alongside the associated image. First, identify any inaccuracies or omissions. Then, provide the corrected version of the sentence(s) or the sentence(s) that should be added. If the report is both accurate and complete, reply with: 'No errors detected.'\\nAnswer Format: '{corrected or added sentence}' or 'No errors detected.'\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 18258.41it/s]\n",
      "100%|██████████| 997/997 [00:00<00:00, 16288.15it/s]\n",
      "100%|██████████| 992/992 [00:00<00:00, 15082.39it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 15865.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def generate_insert_conversations(df, lesion_type, report_col, inserted_sentence_col, question_format, start_index=0):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['classification'])\n",
    "        report = sample[report_col]\n",
    "        distorted_sentence = sample[inserted_sentence_col]\n",
    "\n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: '''{report}'''\"\n",
    "        answer = f\"{distorted_sentence}\"\n",
    "\n",
    "        human_dict = {\n",
    "            'type': 'insertion',\n",
    "            'level': '1',\n",
    "            'lesion': lesion_type,\n",
    "            'from': 'human',\n",
    "            'value': input_text.strip()\n",
    "        }\n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "# 실행 부분\n",
    "full_list = []\n",
    "full_list += generate_insert_conversations(none_insert_nodule, \n",
    "                                           lesion_type='nodule',\n",
    "                                           report_col='insertion_nodule_distorted_report',\n",
    "                                           inserted_sentence_col='insertion_nodule_classification',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=0)\n",
    "\n",
    "full_list += generate_insert_conversations(none_insert_effusion, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='insertion_effusion_distorted_report',\n",
    "                                           inserted_sentence_col='insertion_effusion_classification',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n",
    "\n",
    "full_list += generate_insert_conversations(insertion_effusion, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='insertion_effusion_distorted_report',\n",
    "                                           inserted_sentence_col='insertion_effusion_classification',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n",
    "\n",
    "full_list += generate_insert_conversations(insertion_nodule, \n",
    "                                           lesion_type='nodule',\n",
    "                                           report_col='insertion_nodule_distorted_report',\n",
    "                                           inserted_sentence_col='insertion_nodule_classification',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### omission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 967/967 [00:00<00:00, 16046.67it/s]\n",
      "100%|██████████| 935/935 [00:00<00:00, 16463.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def generate_omit_conversations(df, lesion_type, report_col, inserted_sentence_col, question_format, start_index=0):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['classification'])\n",
    "        report = sample[report_col]\n",
    "        distorted_sentence = sample[inserted_sentence_col]\n",
    "\n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: '''{report}'''\"\n",
    "        answer = f\"{distorted_sentence}\"\n",
    "\n",
    "        human_dict = {\n",
    "            'type': 'omission',\n",
    "            'level': '1',\n",
    "            'lesion': lesion_type,\n",
    "            'from': 'human',\n",
    "            'value': input_text.strip()\n",
    "        }\n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "\n",
    "# 실행 부분\n",
    "full_list += generate_omit_conversations(omission_nodule, \n",
    "                                         lesion_type='nodule',\n",
    "                                         report_col='omission_nodule_distorted_report',\n",
    "                                         inserted_sentence_col='omission_nodule_classification',\n",
    "                                         question_format=question_format,\n",
    "                                         start_index=len(full_list))\n",
    "\n",
    "full_list += generate_omit_conversations(omission_effusion, \n",
    "                                         lesion_type='effusion',\n",
    "                                         report_col='omission_effusion_distorted_report',\n",
    "                                         inserted_sentence_col='omission_effusion_classification',\n",
    "                                         question_format=question_format,\n",
    "                                         start_index=len(full_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 955/955 [00:00<00:00, 10759.62it/s]\n",
      "100%|██████████| 702/702 [00:00<00:00, 16571.93it/s]\n",
      "100%|██████████| 976/976 [00:00<00:00, 19126.30it/s]\n",
      "100%|██████████| 873/873 [00:00<00:00, 13085.37it/s]\n",
      "100%|██████████| 987/987 [00:00<00:00, 15708.23it/s]\n",
      "100%|██████████| 688/688 [00:00<00:00, 14264.37it/s]\n",
      "100%|██████████| 977/977 [00:00<00:00, 13944.00it/s]\n",
      "100%|██████████| 654/654 [00:00<00:00, 15718.01it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def generate_other_conversations(df, report_col, inserted_sentence_col, question_format, type, lesion_type=None, start_index=len(full_list)):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['classification'])\n",
    "        report = sample[report_col]\n",
    "        distorted_sentence = sample[inserted_sentence_col]\n",
    "\n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: '''{report}'''\"\n",
    "        answer = f\"{distorted_sentence}\"\n",
    "        \n",
    "        if lesion_type is not None:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '1',\n",
    "                'lesion': lesion_type,\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }\n",
    "        else:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '1',\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }            \n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "# nodule\n",
    "full_list += generate_other_conversations(direction_nodule, \n",
    "                                          lesion_type='nodule',\n",
    "                                          report_col='direction_nodule_distorted_report',\n",
    "                                          inserted_sentence_col='direction_nodule_classification',\n",
    "                                          type='direction',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(size_nodule, \n",
    "                                          report_col='size_distorted_report',\n",
    "                                          inserted_sentence_col='size_classification',\n",
    "                                          type='size',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(typo_nodule, \n",
    "                                          report_col='typo_distorted_report',\n",
    "                                          inserted_sentence_col='typo_classification',\n",
    "                                          type='typo',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(unit_nodule, \n",
    "                                          report_col='unit_distorted_report',\n",
    "                                          inserted_sentence_col='unit_classification',\n",
    "                                          type='unit',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "\n",
    "\n",
    "# effusion\n",
    "full_list += generate_other_conversations(direction_effusion, \n",
    "                                          lesion_type='effusion',\n",
    "                                          report_col='direction_effusion_distorted_report',\n",
    "                                          inserted_sentence_col='direction_effusion_classification',\n",
    "                                          type='direction',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(size_effusion, \n",
    "                                          report_col='size_distorted_report',\n",
    "                                          inserted_sentence_col='size_classification',\n",
    "                                          type='size',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(typo_effusion, \n",
    "                                          report_col='typo_distorted_report',\n",
    "                                          inserted_sentence_col='typo_classification',\n",
    "                                          type='typo',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(unit_effusion, \n",
    "                                          report_col='unit_distorted_report',\n",
    "                                          inserted_sentence_col='unit_classification',\n",
    "                                          type='unit',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No erros detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 12457.98it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 14079.10it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8495.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def generate_normal_conversations(df, report_col, question_format, type, lesion_type=None, start_index=len(full_list)):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['classification'])\n",
    "        report = sample[report_col]\n",
    "\n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: '''{report}'''\"\n",
    "        answer = \"0\"\n",
    "        \n",
    "        if lesion_type is not None:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '1',\n",
    "                'lesion': lesion_type,\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }\n",
    "        else:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '1',\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }            \n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "\n",
    "# normal\n",
    "full_list += generate_normal_conversations(nodule_sample_df, \n",
    "                                           lesion_type='nodule',\n",
    "                                           report_col='lung_parenchyma',\n",
    "                                           type='normal',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n",
    "\n",
    "full_list += generate_normal_conversations(effusion_sample_df, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='lung_parenchyma',\n",
    "                                           type='normal',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list)) \n",
    "\n",
    "full_list += generate_normal_conversations(none_sample_df, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='lung_parenchyma',\n",
    "                                           type='normal',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15703"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 17455.97it/s]\n",
      "100%|██████████| 997/997 [00:00<00:00, 20364.07it/s]\n",
      "100%|██████████| 992/992 [00:00<00:00, 21291.10it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 21512.23it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def generate_insert_conversations(df, lesion_type, report_col, inserted_sentence_col, question_format, start_index=0):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['detection'])\n",
    "        report = sample[report_col]\n",
    "        distorted_sentence = sample[inserted_sentence_col]\n",
    "\n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: '''{report}'''\"\n",
    "        answer = f\"{distorted_sentence}\"\n",
    "\n",
    "        human_dict = {\n",
    "            'type': 'insertion',\n",
    "            'level': '2',\n",
    "            'lesion': lesion_type,\n",
    "            'from': 'human',\n",
    "            'value': input_text.strip()\n",
    "        }\n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "full_list += generate_insert_conversations(none_insert_nodule, \n",
    "                                           lesion_type='nodule',\n",
    "                                           report_col='insertion_nodule_distorted_report',\n",
    "                                           inserted_sentence_col='insertion_nodule_inserted_sentence',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n",
    "\n",
    "full_list += generate_insert_conversations(none_insert_effusion, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='insertion_effusion_distorted_report',\n",
    "                                           inserted_sentence_col='insertion_effusion_inserted_sentence',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n",
    "\n",
    "full_list += generate_insert_conversations(insertion_effusion, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='insertion_effusion_distorted_report',\n",
    "                                           inserted_sentence_col='insertion_effusion_inserted_sentence',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n",
    "\n",
    "full_list += generate_insert_conversations(insertion_nodule, \n",
    "                                           lesion_type='nodule',\n",
    "                                           report_col='insertion_nodule_distorted_report',\n",
    "                                           inserted_sentence_col='insertion_nodule_inserted_sentence',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 955/955 [00:00<00:00, 16521.18it/s]\n",
      "100%|██████████| 702/702 [00:00<00:00, 16347.52it/s]\n",
      "100%|██████████| 976/976 [00:00<00:00, 16548.05it/s]\n",
      "100%|██████████| 873/873 [00:00<00:00, 20816.65it/s]\n",
      "100%|██████████| 987/987 [00:00<00:00, 18607.75it/s]\n",
      "100%|██████████| 688/688 [00:00<00:00, 20365.58it/s]\n",
      "100%|██████████| 977/977 [00:00<00:00, 18407.97it/s]\n",
      "100%|██████████| 654/654 [00:00<00:00, 6228.71it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def generate_other_conversations(df, report_col, inserted_sentence_col, question_format, type, lesion_type=None, start_index=len(full_list)):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['detection'])\n",
    "        report = sample[report_col]\n",
    "        distorted_sentence = sample[inserted_sentence_col]\n",
    "\n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: '''{report}'''\"\n",
    "        answer = f\"{distorted_sentence}\"\n",
    "        \n",
    "        if lesion_type is not None:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '2',\n",
    "                'lesion': lesion_type,\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }\n",
    "        else:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '2',\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }            \n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "# nodule\n",
    "full_list += generate_other_conversations(direction_nodule, \n",
    "                                          lesion_type='nodule',\n",
    "                                          report_col='direction_nodule_distorted_report',\n",
    "                                          inserted_sentence_col='direction_nodule_distorted_sentence',\n",
    "                                          type='direction',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(size_nodule, \n",
    "                                          report_col='size_distorted_report',\n",
    "                                          inserted_sentence_col='size_distorted_sentence',\n",
    "                                          type='size',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(typo_nodule, \n",
    "                                          report_col='typo_distorted_report',\n",
    "                                          inserted_sentence_col='typo_distorted_sentence',\n",
    "                                          type='typo',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(unit_nodule, \n",
    "                                          report_col='unit_distorted_report',\n",
    "                                          inserted_sentence_col='unit_distorted_sentence',\n",
    "                                          type='unit',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "\n",
    "\n",
    "# effusion\n",
    "full_list += generate_other_conversations(direction_effusion, \n",
    "                                          lesion_type='effusion',\n",
    "                                          report_col='direction_effusion_distorted_report',\n",
    "                                          inserted_sentence_col='direction_effusion_distorted_sentence',\n",
    "                                          type='direction',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(size_effusion, \n",
    "                                          report_col='size_distorted_report',\n",
    "                                          inserted_sentence_col='size_distorted_sentence',\n",
    "                                          type='size',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(typo_effusion, \n",
    "                                          report_col='typo_distorted_report',\n",
    "                                          inserted_sentence_col='typo_distorted_sentence',\n",
    "                                          type='typo',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(unit_effusion, \n",
    "                                          report_col='unit_distorted_report',\n",
    "                                          inserted_sentence_col='unit_distorted_sentence',\n",
    "                                          type='unit',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No erros detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 21918.85it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 21703.24it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 26075.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def generate_normal_conversations(df, report_col, question_format, type, lesion_type=None, start_index=len(full_list)):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['detection'])\n",
    "        report = sample[report_col]\n",
    "\n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: '''{report}'''\"\n",
    "        answer = \"No errors detected.\"\n",
    "        \n",
    "        if lesion_type is not None:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '2',\n",
    "                'lesion': lesion_type,\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }\n",
    "        else:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '2',\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }            \n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "\n",
    "# normal\n",
    "full_list += generate_normal_conversations(nodule_sample_df, \n",
    "                                           lesion_type='nodule',\n",
    "                                           report_col='lung_parenchyma',\n",
    "                                           type='normal',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n",
    "\n",
    "full_list += generate_normal_conversations(effusion_sample_df, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='lung_parenchyma',\n",
    "                                           type='normal',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list)) \n",
    "\n",
    "full_list += generate_normal_conversations(none_sample_df, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='lung_parenchyma',\n",
    "                                           type='normal',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29504"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level 2 - indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_sentence_index(report: str, target_sentence: str, threshold: int = 4) -> int:\n",
    "    # 문장 추출\n",
    "    sentences = re.findall(r'\\d+\\.\\s+(.*?)(?=\\n\\d+\\.|\\Z)', report, re.DOTALL)\n",
    "\n",
    "    # 전처리된 타겟 단어 리스트\n",
    "    target_words = set(target_sentence.strip().lower().rstrip('.').split())\n",
    "\n",
    "    # 문장별로 중복 단어 수 체크\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        sentence_words = set(sentence.strip().lower().rstrip('.').split())\n",
    "        common_words = target_words & sentence_words\n",
    "        \n",
    "        if len(common_words) >= threshold:\n",
    "            return idx + 1  # 1-based index\n",
    "    return -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 14153.50it/s]\n",
      "100%|██████████| 997/997 [00:00<00:00, 13051.40it/s]\n",
      "100%|██████████| 992/992 [00:00<00:00, 10014.58it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8849.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def generate_insert_conversations(df, lesion_type, report_col, inserted_sentence_col, question_format, start_index=0):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['detection_index'])\n",
    "        report = sample[report_col]\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', report.strip())\n",
    "        numbered_text = '\\n'.join(f\"{i+1}. {sentence}\" for i, sentence in enumerate(sentences))\n",
    "        distorted_sentence = sample[inserted_sentence_col]\n",
    "        index = find_sentence_index(numbered_text, distorted_sentence)\n",
    "\n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: \\n'''\\n{numbered_text}\\n'''\"\n",
    "        answer = f\"{index}\"\n",
    "\n",
    "        human_dict = {\n",
    "            'type': 'insertion',\n",
    "            'level': '2',\n",
    "            'lesion': lesion_type,\n",
    "            'from': 'human',\n",
    "            'value': input_text.strip()\n",
    "        }\n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip(),\n",
    "            'distorted_sentence': distorted_sentence.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "full_list += generate_insert_conversations(none_insert_nodule, \n",
    "                                           lesion_type='nodule',\n",
    "                                           report_col='insertion_nodule_distorted_report',\n",
    "                                           inserted_sentence_col='insertion_nodule_inserted_sentence',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n",
    "\n",
    "full_list += generate_insert_conversations(none_insert_effusion, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='insertion_effusion_distorted_report',\n",
    "                                           inserted_sentence_col='insertion_effusion_inserted_sentence',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n",
    "\n",
    "full_list += generate_insert_conversations(insertion_effusion, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='insertion_effusion_distorted_report',\n",
    "                                           inserted_sentence_col='insertion_effusion_inserted_sentence',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n",
    "\n",
    "full_list += generate_insert_conversations(insertion_nodule, \n",
    "                                           lesion_type='nodule',\n",
    "                                           report_col='insertion_nodule_distorted_report',\n",
    "                                           inserted_sentence_col='insertion_nodule_inserted_sentence',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect report-image errors. Output the index of each erroneous sentence. If there are no errors, respond with '0' to indicate all sentences are correct.\n",
      "Answer Format: '{index}' or '0'\n",
      "Here is the medical report: \n",
      "'''\n",
      "1. Atelectasis was observed adjacent to the effusion in the lower lobes of both lungs.\n",
      "2. There are emphysematous changes in both lungs.\n",
      "3. There is bilateral pleural effusion.\n",
      "4. The pleural effusion measured 40 mm at its thickest point.\n",
      "5. A 1.7 cm nodule with a lobulated border in the left lower lobe.\n",
      "'''\n",
      "5\n",
      "A 1.7 cm nodule with a lobulated border in the left lower lobe.\n"
     ]
    }
   ],
   "source": [
    "print(full_list[-1]['conversations'][0]['value'])\n",
    "print(full_list[-1]['conversations'][1]['value'])\n",
    "print(full_list[-1]['conversations'][1]['distorted_sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 955/955 [00:00<00:00, 10814.94it/s]\n",
      "100%|██████████| 702/702 [00:00<00:00, 10101.24it/s]\n",
      "100%|██████████| 976/976 [00:00<00:00, 10329.29it/s]\n",
      "100%|██████████| 873/873 [00:00<00:00, 5314.18it/s]\n",
      "100%|██████████| 987/987 [00:00<00:00, 9666.73it/s]\n",
      "100%|██████████| 688/688 [00:00<00:00, 9878.95it/s]\n",
      "100%|██████████| 977/977 [00:00<00:00, 9446.50it/s]\n",
      "100%|██████████| 654/654 [00:00<00:00, 10227.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def generate_other_conversations(df, report_col, inserted_sentence_col, question_format, type, lesion_type=None, start_index=len(full_list)):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['detection_index'])\n",
    "        report = sample[report_col]\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', report.strip())\n",
    "        numbered_text = '\\n'.join(f\"{i+1}. {sentence}\" for i, sentence in enumerate(sentences))\n",
    "        distorted_sentence = sample[inserted_sentence_col]\n",
    "        index = find_sentence_index(numbered_text, distorted_sentence)\n",
    "\n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: \\n'''\\n{numbered_text}\\n'''\"\n",
    "        answer = f\"{index}\"\n",
    "        \n",
    "        if lesion_type is not None:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '2',\n",
    "                'lesion': lesion_type,\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }\n",
    "        else:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '2',\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }            \n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip(),\n",
    "            'distorted_sentence': distorted_sentence.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "# nodule\n",
    "full_list += generate_other_conversations(direction_nodule, \n",
    "                                          lesion_type='nodule',\n",
    "                                          report_col='direction_nodule_distorted_report',\n",
    "                                          inserted_sentence_col='direction_nodule_distorted_sentence',\n",
    "                                          type='direction',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(size_nodule, \n",
    "                                          report_col='size_distorted_report',\n",
    "                                          inserted_sentence_col='size_distorted_sentence',\n",
    "                                          type='size',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(typo_nodule, \n",
    "                                          report_col='typo_distorted_report',\n",
    "                                          inserted_sentence_col='typo_distorted_sentence',\n",
    "                                          type='typo',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(unit_nodule, \n",
    "                                          report_col='unit_distorted_report',\n",
    "                                          inserted_sentence_col='unit_distorted_sentence',\n",
    "                                          type='unit',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "\n",
    "\n",
    "# effusion\n",
    "full_list += generate_other_conversations(direction_effusion, \n",
    "                                          lesion_type='effusion',\n",
    "                                          report_col='direction_effusion_distorted_report',\n",
    "                                          inserted_sentence_col='direction_effusion_distorted_sentence',\n",
    "                                          type='direction',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(size_effusion, \n",
    "                                          report_col='size_distorted_report',\n",
    "                                          inserted_sentence_col='size_distorted_sentence',\n",
    "                                          type='size',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(typo_effusion, \n",
    "                                          report_col='typo_distorted_report',\n",
    "                                          inserted_sentence_col='typo_distorted_sentence',\n",
    "                                          type='typo',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(unit_effusion, \n",
    "                                          report_col='unit_distorted_report',\n",
    "                                          inserted_sentence_col='unit_distorted_sentence',\n",
    "                                          type='unit',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the medical report for any errors, including mismatches with the image. If any such issues are found, return the index numbers of the sentences involved. If everything is consistent, output '0' to indicate no errors.\n",
      "Answer Format: '{index}' or '0'\n",
      "Here is the medical report: \n",
      "'''\n",
      "1. There is compression atelectesis in the accompanying lung parenchyma.\n",
      "2. There are areas of linear atelectasis in the lower lobe of the left lung, and there are areas of consolidation that may be compatible with interlober-intralobular signal thickness increases and effusion in places in the lower lobe of both lungs.\n",
      "3. The volume of the lower lobe of the right lung has decreased, and a consolidation area consistent with ataelactasia is observed in the lower lobe of the right lung.\n",
      "4. There are ground glass opacities in the parenchyma around the consolidation area.\n",
      "5. When examined in the lung parenchyma window; Pleural effusion reaching 4 mm in the thickest part of the right lung is observed.\n",
      "'''\n",
      "1\n",
      "Pleural effusion reaching 4 mm in the thickest part of the right lung is observed.\n"
     ]
    }
   ],
   "source": [
    "print(full_list[-3]['conversations'][0]['value'])\n",
    "print(full_list[-3]['conversations'][1]['value'])\n",
    "print(full_list[-3]['conversations'][1]['distorted_sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No erros detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 16879.91it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 14835.54it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 21019.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def generate_normal_conversations(df, report_col, question_format, type, lesion_type=None, start_index=len(full_list)):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['detection_index'])\n",
    "        report = sample[report_col]\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', report.strip())\n",
    "        numbered_text = '\\n'.join(f\"{i+1}. {sentence}\" for i, sentence in enumerate(sentences))\n",
    "\n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: \\n'''\\n{numbered_text}\\n'''\"\n",
    "        answer = \"0\"\n",
    "        \n",
    "        if lesion_type is not None:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '2',\n",
    "                'lesion': lesion_type,\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }\n",
    "        else:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '2',\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }            \n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "\n",
    "# normal\n",
    "full_list += generate_normal_conversations(nodule_sample_df, \n",
    "                                           lesion_type='nodule',\n",
    "                                           report_col='lung_parenchyma',\n",
    "                                           type='normal',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n",
    "\n",
    "full_list += generate_normal_conversations(effusion_sample_df, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='lung_parenchyma',\n",
    "                                           type='normal',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list)) \n",
    "\n",
    "full_list += generate_normal_conversations(none_sample_df, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='lung_parenchyma',\n",
    "                                           type='normal',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43305"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highlight any incorrect, mismatched, or erroneous sentences in the medical report, including those that conflict with the provided image. If the report is fully accurate, clearly respond with '0' to show that no errors were found.\n",
      "Answer Format: '{index}' or '0'\n",
      "Here is the medical report: \n",
      "'''\n",
      "1. In the evaluation of both lung parenchyma; No mass nodule infiltration was observed in both lung parenchyma.\n",
      "2. Pleural effusion-thickening was not detected in both hemithorax.\n",
      "'''\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(full_list[-1]['conversations'][0]['value'])\n",
    "print(full_list[-1]['conversations'][1]['value'])\n",
    "# print(full_list[-1]['conversations'][1]['distorted_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report_generation_38966 train_484_a_1.nii.gz\n",
      "Highlight any incorrect, mismatched, or erroneous sentences in the medical report, including those that conflict with the provided image. If the report is fully accurate, clearly respond with '0' to show that no errors were found.\n",
      "Answer Format: '{index}' or '0'\n",
      "Here is the medical report: \n",
      "'''\n",
      "1. Segmentary-subsegmental tubular bronchiectasis and peribronchial thickening were observed in both lungs.\n",
      "2. In addition, 97x50 mm sized infected bulla formation with air-fluid leveling was observed in the right lung lower lobe basal.\n",
      "3. Other findings are stable.\n",
      "4. Emphysema areas are panacinar in the right lung lower lobe basal and left lung upper lobe apical segments.\n",
      "5. It is stable.\n",
      "6. Bula formations were observed in the left lung apex and in the left inferior lingular segment.\n",
      "7. Diffuse paraseptal-centracinar emphysema areas were observed in both lungs.\n",
      "8. A pleural effusion measuring 10 mm in the deepest part on the right (17.8 mm in the previous examination) and 15 mm in the deepest part on the left (24 mm in the previous examination) was observed between the pleural leaves in both hemithorax with peribronchial thikening.\n",
      "'''\n",
      "-1\n",
      "with peribronchial thikening.\n",
      "---\n",
      "report_generation_39112 train_12198_b_1.nii.gz\n",
      "Scan the medical report for any errors or factual discrepancies in comparison to the image. Return the index numbers of any erroneous sentences. If no such sentences exist, respond with '0' to indicate no issues were detected.\n",
      "Answer Format: '{index}' or '0'\n",
      "Here is the medical report: \n",
      "'''\n",
      "1. blind.\n",
      "2. Due to the current pandemic, clinical lab.\n",
      "3. When examined in the lung parenchyma window; aeration of both lung parenchyma is normal, and light ground glass densities in the upper lobe inferior lingula and middle lobe medial in the lung parenchyma were primarily evaluated in favor of atelectasics changes.\n",
      "4. Bilateral pleural effusion and pleural thickenings observed in the previous examination show significant regression in the current examination, and there are mild pleural thickenings in the upper lobe anterior and lower lobe posterior on the left side, and a smearing pleural effusion.\n",
      "'''\n",
      "-1\n",
      "atelectasics\n",
      "---\n",
      "report_generation_39226 train_11399_a_1.nii.gz\n",
      "Detect report-image errors. Output the index of each erroneous sentence. If there are no errors, respond with '0' to indicate all sentences are correct.\n",
      "Answer Format: '{index}' or '0'\n",
      "Here is the medical report: \n",
      "'''\n",
      "1. Pneunomic infiltration?\n",
      "2. Basals have bronchiectasis.\n",
      "3. In the evaluation of both lung parenchyma; In the bilateral lungs, especially in the middle and lower zones, consolidations and ground-glass densities were observed with prominent patches of air bronchogram with a tendency to coalesce.\n",
      "4. Bilateral minimal pleural effusion was observed.\n",
      "'''\n",
      "-1\n",
      "Pneunomic infiltration?\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in full_list:\n",
    "    if i['conversations'][1]['value'] == \"-1\":\n",
    "        cnt += 1\n",
    "        print(i['id'], i['image'])\n",
    "        print(i['conversations'][0]['value'])\n",
    "        print(i['conversations'][1]['value'])\n",
    "        print(i['conversations'][1]['distorted_sentence'])\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in full_list:\n",
    "    if i['id'] == \"report_generation_38966\":\n",
    "        i['conversations'][1]['value'] = \"8\"\n",
    "\n",
    "    elif i['id'] == \"report_generation_39112\":\n",
    "        i['conversations'][1]['value'] = \"3\"    \n",
    "\n",
    "    elif i['id'] == \"report_generation_39226\":\n",
    "        i['conversations'][1]['value'] = \"1\"        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in full_list:\n",
    "    if i['conversations'][1]['value'] == \"-1\":\n",
    "        print(i['id'])\n",
    "        print(i['conversations'][0]['value'])\n",
    "        print(i['conversations'][1]['value'])\n",
    "        print(i['conversations'][1]['distorted_sentence'])\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### omission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 967/967 [00:00<00:00, 11592.04it/s]\n",
      "100%|██████████| 935/935 [00:00<00:00, 18851.12it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def generate_omit_conversations(df, lesion_type, report_col, inserted_sentence_col, question_format, start_index=0):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['correction'])\n",
    "        report = sample[report_col]\n",
    "        corrected_sentence = sample[inserted_sentence_col]\n",
    "\n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: '''{report}'''\"\n",
    "        answer = f\"{corrected_sentence}\"\n",
    "\n",
    "        human_dict = {\n",
    "            'type': 'omission',\n",
    "            'level': '3',\n",
    "            'lesion': lesion_type,\n",
    "            'from': 'human',\n",
    "            'value': input_text.strip()\n",
    "        }\n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "# 실행 부분\n",
    "full_list += generate_omit_conversations(omission_nodule, \n",
    "                                         lesion_type='nodule',\n",
    "                                         report_col='omission_nodule_distorted_report',\n",
    "                                         inserted_sentence_col='omission_nodule_deleted_sentence',\n",
    "                                         question_format=question_format,\n",
    "                                         start_index=len(full_list))\n",
    "\n",
    "full_list += generate_omit_conversations(omission_effusion, \n",
    "                                         lesion_type='effusion',\n",
    "                                         report_col='omission_effusion_distorted_report',\n",
    "                                         inserted_sentence_col='omission_effusion_deleted_sentence',\n",
    "                                         question_format=question_format,\n",
    "                                         start_index=len(full_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 955/955 [00:00<00:00, 10565.00it/s]\n",
      "100%|██████████| 702/702 [00:00<00:00, 17634.31it/s]\n",
      "100%|██████████| 976/976 [00:00<00:00, 19503.56it/s]\n",
      "100%|██████████| 873/873 [00:00<00:00, 20474.66it/s]\n",
      "100%|██████████| 987/987 [00:00<00:00, 21201.80it/s]\n",
      "100%|██████████| 688/688 [00:00<00:00, 20200.21it/s]\n",
      "100%|██████████| 977/977 [00:00<00:00, 21015.40it/s]\n",
      "100%|██████████| 654/654 [00:00<00:00, 19859.51it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def generate_other_conversations(df, report_col, inserted_sentence_col, corrected_sentence_col, question_format, type, lesion_type=None, start_index=len(full_list)):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['correction'])\n",
    "        report = sample[report_col]\n",
    "        corrected_sentence = sample[corrected_sentence_col]\n",
    "        \n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: '''{report}'''\"\n",
    "        answer = f\"{corrected_sentence}\"\n",
    "        \n",
    "        if lesion_type is not None:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '3',\n",
    "                'lesion': lesion_type,\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }\n",
    "        else:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '3',\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }            \n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "# nodule\n",
    "full_list += generate_other_conversations(direction_nodule, \n",
    "                                          lesion_type='nodule',\n",
    "                                          report_col='direction_nodule_distorted_report',\n",
    "                                          inserted_sentence_col='direction_nodule_distorted_sentence',\n",
    "                                          corrected_sentence_col='direction_nodule_corrected_sentence',\n",
    "                                          type='direction',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(size_nodule, \n",
    "                                          report_col='size_distorted_report',\n",
    "                                          inserted_sentence_col='size_distorted_sentence',\n",
    "                                          corrected_sentence_col='size_corrected_sentence',\n",
    "                                          type='size',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(typo_nodule, \n",
    "                                          report_col='typo_distorted_report',\n",
    "                                          inserted_sentence_col='typo_distorted_sentence',\n",
    "                                          corrected_sentence_col='typo_corrected_sentence',\n",
    "                                          type='typo',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(unit_nodule, \n",
    "                                          report_col='unit_distorted_report',\n",
    "                                          inserted_sentence_col='unit_distorted_sentence',\n",
    "                                          corrected_sentence_col='unit_corrected_sentence',\n",
    "                                          type='unit',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "\n",
    "\n",
    "# effusion\n",
    "full_list += generate_other_conversations(direction_effusion, \n",
    "                                          lesion_type='effusion',\n",
    "                                          report_col='direction_effusion_distorted_report',\n",
    "                                          inserted_sentence_col='direction_effusion_distorted_sentence',\n",
    "                                          corrected_sentence_col='direction_effusion_corrected_sentence',\n",
    "                                          type='direction',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(size_effusion, \n",
    "                                          report_col='size_distorted_report',\n",
    "                                          inserted_sentence_col='size_distorted_sentence',\n",
    "                                          corrected_sentence_col='size_corrected_sentence',\n",
    "                                          type='size',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(typo_effusion, \n",
    "                                          report_col='typo_distorted_report',\n",
    "                                          inserted_sentence_col='typo_distorted_sentence',\n",
    "                                          corrected_sentence_col='typo_corrected_sentence',\n",
    "                                          type='typo',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n",
    "\n",
    "full_list += generate_other_conversations(unit_effusion, \n",
    "                                          report_col='unit_distorted_report',\n",
    "                                          inserted_sentence_col='unit_distorted_sentence',\n",
    "                                          corrected_sentence_col='unit_corrected_sentence',\n",
    "                                          type='unit',\n",
    "                                          question_format=question_format,\n",
    "                                          start_index=len(full_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No erros detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 19506.58it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 21745.89it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 25627.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def generate_normal_conversations(df, report_col, question_format, type, lesion_type=None, start_index=len(full_list)):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        sample = df.iloc[i]\n",
    "        cls_prompt = random.choice(question_format['correction'])\n",
    "        report = sample[report_col]\n",
    "\n",
    "        input_text = f\"{cls_prompt}\\nHere is the medical report: '''{report}'''\"\n",
    "        answer = \"No errors detected.\"\n",
    "        \n",
    "        if lesion_type is not None:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '3',\n",
    "                'lesion': lesion_type,\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }\n",
    "        else:\n",
    "            human_dict = {\n",
    "                'type': type,\n",
    "                'level': '3',\n",
    "                'from': 'human',\n",
    "                'value': input_text.strip()\n",
    "            }            \n",
    "\n",
    "        gpt_dict = {\n",
    "            'from': 'gpt',\n",
    "            'value': answer.strip()\n",
    "        }\n",
    "\n",
    "        conversation = [human_dict, gpt_dict]\n",
    "\n",
    "        data_dict = {\n",
    "            'id': f'report_generation_{start_index + i}',\n",
    "            'image': sample['id'],\n",
    "            'conversations': conversation\n",
    "        }\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "# normal\n",
    "full_list += generate_normal_conversations(nodule_sample_df, \n",
    "                                           lesion_type='nodule',\n",
    "                                           report_col='lung_parenchyma',\n",
    "                                           type='normal',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list))\n",
    "\n",
    "full_list += generate_normal_conversations(effusion_sample_df, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='lung_parenchyma',\n",
    "                                           type='normal',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list)) \n",
    "\n",
    "full_list += generate_normal_conversations(none_sample_df, \n",
    "                                           lesion_type='effusion',\n",
    "                                           report_col='lung_parenchyma',\n",
    "                                           type='normal',\n",
    "                                           question_format=question_format,\n",
    "                                           start_index=len(full_list)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55019"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fixed 경로 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "train_meta_list = glob.glob(\"/workspace/5.Lung/datasets/CT-RATE-Revised/dataset/train_fixed/*/*/*.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(train_meta_list, columns=['image_path'])\n",
    "\n",
    "list_train = [i['image'] for i in full_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for i in range(len(list_train)):\n",
    "    new_list.append(df[df['image_path'].str.contains(list_train[i])].values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55019, 55019, 23887, 55019)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_list), len(list_train), len(df), len(full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(full_list)):\n",
    "    full_list[i]['image_path'] = new_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new.json\", \"w\") as f:\n",
    "    json.dump(full_list, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_1_list = []\n",
    "level_2_list = []\n",
    "level_3_list = []\n",
    "\n",
    "for i in full_list:\n",
    "    if i['conversations'][0]['level'] == \"1\":\n",
    "        level_1_list.append(i)\n",
    "    elif i['conversations'][0]['level'] == \"2\":\n",
    "        level_2_list.append(i)\n",
    "    elif i['conversations'][0]['level'] == \"3\":\n",
    "        level_3_list.append(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/workspace/7.Error/error_full_list_final_new_level1.json\", \"w\") as f:\n",
    "    json.dump(level_1_list, f, indent=4)\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new_level2.json\", \"w\") as f:\n",
    "    json.dump(level_2_list[:-13801], f, indent=4)\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new_level2_index.json\", \"w\") as f:\n",
    "    json.dump(level_2_list[-13801:], f, indent=4)\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new_level3.json\", \"w\") as f:\n",
    "    json.dump(level_3_list, f, indent=4)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RadFM style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nii.gz load 하고, resize 512x512로 resize, 그리고 복사해서 3 ch 만듬.\n",
    "# depth 축을 64로 ndimage.zoom을 이용하여 구축.\n",
    "# min max normalization 후에 torch tensor로 변환.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install einops==0.6.1\n",
    "# !pip install einops-exts==0.0.4\n",
    "# !pip install huggingface-hub==0.16.4\n",
    "# !pip install nibabel==5.1.0\n",
    "# !pip install nmslib==2.1.1\n",
    "# !pip install opencv-python==4.8.0.76\n",
    "# !pip install pandas==2.0.3\n",
    "# !pip install Pillow==9.4.0\n",
    "# !pip install pytz==2023.3\n",
    "# !pip install PyYAML==6.0.1\n",
    "# !pip install scikit-learn==1.3.0\n",
    "# !pip install scipy==1.11.2\n",
    "# !pip install scispacy\n",
    "# !pip install sentencepiece==0.1.99\n",
    "# !pip install SimpleITK==2.2.1\n",
    "# !pip install spacy==3.6.1\n",
    "# !pip install spacy-alignments==0.9.0\n",
    "# !pip install spacy-legacy==3.0.12\n",
    "# !pip install spacy-loggers==1.0.4\n",
    "# !pip install spacy-transformers==1.2.5\n",
    "# !pip install tokenizers==0.13.3\n",
    "# !pip install torch==2.0.1\n",
    "# !pip install torchaudio==2.0.2\n",
    "# !pip install torchvision==0.15.2\n",
    "# !pip install tqdm==4.66.1\n",
    "# !pip install transformers==4.28.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M3D style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The image shape needs to be processed as 1*32*256*256, consider resize and other methods.\n",
    "# 2. The image needs to be normalized to 0-1, consider Min-Max Normalization.\n",
    "# 3. The image format needs to be converted to .npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepspeed==0.13.4\n",
    "# einops==0.8.0\n",
    "# evaluate==0.4.1\n",
    "# matplotlib==3.8.4\n",
    "# monai==1.3.0\n",
    "# nibabel==5.2.1\n",
    "# numpy==1.26.4\n",
    "# opencv_python==4.9.0.80\n",
    "# pandas==2.2.2\n",
    "# peft==0.8.2\n",
    "# Pillow==10.3.0\n",
    "# pycocotools==2.0.7\n",
    "# Requests==2.31.0\n",
    "# rouge==1.0.1\n",
    "# safetensors==0.4.3\n",
    "# scipy==1.13.0\n",
    "# simple_slice_viewer==0.97\n",
    "# SimpleITK==2.3.1\n",
    "# torch==2.2.1+cu118\n",
    "# torchvision==0.17.1+cu118\n",
    "# tqdm==4.66.2\n",
    "# transformers==4.39.1\n",
    "# tweepy==4.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CT-CHAT style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new.json\", \"r\") as f:\n",
    "    full_list = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(full_list)):\n",
    "    # full_list[i]['conversations'][0]['value'] = \"<image>\\n\" + full_list[i]['conversations'][0]['value'] + ' <report_generation>'\n",
    "\n",
    "    if full_list[i]['conversations'][0]['level'] == '1':\n",
    "        full_list[i]['conversations'][0]['value'] = \"<image>\\n\" + full_list[i]['conversations'][0]['value'] + \" <short_answer>\"\n",
    "    else:\n",
    "        full_list[i]['conversations'][0]['value'] = \"<image>\\n\" + full_list[i]['conversations'][0]['value'] + \" <long_answer>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new_ctchat.json\", \"w\") as f:\n",
    "    json.dump(full_list, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new_level1.json\", \"r\") as f:\n",
    "    level_1_list = json.load(f)\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new_level2.json\", \"r\") as f:\n",
    "    level_2_list = json.load(f)\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new_level2_index.json\", \"r\") as f:\n",
    "    level_2_list_index = json.load(f)\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new_level3.json\", \"r\") as f:\n",
    "    level_3_list = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(level_1_list)):\n",
    "    if level_1_list[i]['conversations'][0]['level'] == '1':\n",
    "        level_1_list[i]['conversations'][0]['value'] = \"<image>\\n\" + level_1_list[i]['conversations'][0]['value'] + \" <short_answer>\"\n",
    "    else:\n",
    "        level_1_list[i]['conversations'][0]['value'] = \"<image>\\n\" + level_1_list[i]['conversations'][0]['value'] + \" <long_answer>\"\n",
    "\n",
    "for i in range(len(level_2_list)):\n",
    "    if level_2_list[i]['conversations'][0]['level'] == '1':\n",
    "        level_2_list[i]['conversations'][0]['value'] = \"<image>\\n\" + level_2_list[i]['conversations'][0]['value'] + \" <short_answer>\"\n",
    "    else:\n",
    "        level_2_list[i]['conversations'][0]['value'] = \"<image>\\n\" + level_2_list[i]['conversations'][0]['value'] + \" <long_answer>\"\n",
    "\n",
    "for i in range(len(level_2_list_index)):\n",
    "    if level_2_list_index[i]['conversations'][0]['level'] == '1':\n",
    "        level_2_list_index[i]['conversations'][0]['value'] = \"<image>\\n\" + level_2_list_index[i]['conversations'][0]['value'] + \" <short_answer>\"\n",
    "    else:\n",
    "        level_2_list_index[i]['conversations'][0]['value'] = \"<image>\\n\" + level_2_list_index[i]['conversations'][0]['value'] + \" <long_answer>\"\n",
    "\n",
    "for i in range(len(level_3_list)):\n",
    "    if level_3_list[i]['conversations'][0]['level'] == '1':\n",
    "        level_3_list[i]['conversations'][0]['value'] = \"<image>\\n\" + level_3_list[i]['conversations'][0]['value'] + \" <short_answer>\"\n",
    "    else:\n",
    "        level_3_list[i]['conversations'][0]['value'] = \"<image>\\n\" + level_3_list[i]['conversations'][0]['value'] + \" <long_answer>\"                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/workspace/7.Error/error_full_list_final_new_level1_ctchat.json\", \"w\") as f:\n",
    "    json.dump(level_1_list, f, indent=4)\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new_level2_ctchat.json\", \"w\") as f:\n",
    "    json.dump(level_2_list, f, indent=4)\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new_level2_index_ctchat.json\", \"w\") as f:\n",
    "    json.dump(level_2_list_index, f, indent=4)\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new_level3_ctchat.json\", \"w\") as f:\n",
    "    json.dump(level_3_list, f, indent=4)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# \"/workspace/7.Error/error_full_list_final.json\" 읽기\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new.json\", \"r\") as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55019"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['conversations'][0]['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = []\n",
    "for i in data:\n",
    "    type_list.append(i['conversations'][0]['type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.unique(type_list, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['direction', 'insertion', 'no errors', 'omission', 'size', 'typo', 'unit']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "define = '''There are 7 possible scenarios you should consider:\n",
    "1. Omission: Check if any nodule, mass, or effusion visible in the CT imaging is missing from the report. Ensure all significant findings observed in the CT scan are documented in the report.\n",
    "2. Insertion: Verify that all abnormal findings described in the report actually correspond to the current patient's CT imaging. Look for sentences that may have been inappropriately inserted from templates or unrelated cases.\n",
    "3. Direction: Confirm that directional terms (right/left, upper/lower, unilateral/bilateral, both) used to describe nodules, masses, or effusions match the actual locations in the CT imaging. The laterality or position may have been incorrectly switched.\n",
    "4. Size: Validate that the size measurements of lesions in the report accurately reflect the actual dimensions in the CT imaging. The reported values may be incorrectly stated as 50% larger or smaller than the true measurements.\n",
    "5. Unit: Check that measurement units (cm, mm, m) are appropriate and correct. Unit errors can significantly misrepresent the actual size of lesions.\n",
    "6. Typo: Review medical terminology for spelling errors. A single character typo can alter or obscure the intended medical meaning.\n",
    "7. No errors: The report may be completely accurate with no errors present. Not all reports contain mistakes.'''\n",
    "\n",
    "def insert_define_after_first_sentence(question_text: str, define: str) -> str:\n",
    "    \"\"\"\n",
    "    첫 문장 뒤에 정의문을 삽입하는 함수.\n",
    "    \n",
    "    Parameters:\n",
    "    - question_text (str): 원본 질문 텍스트\n",
    "    - define (str): 삽입할 정의문 텍스트\n",
    "    \n",
    "    Returns:\n",
    "    - str: define이 첫 문장 뒤에 삽입된 최종 문자열\n",
    "    \"\"\"\n",
    "    question_text = question_text.strip()\n",
    "\n",
    "    match = re.search(r\"^(.*?\\.)\", question_text)\n",
    "    if match:\n",
    "        insert_index = match.end()\n",
    "        result = question_text[:insert_index].strip() + \"\\n\" + define + \"\\n\" + question_text[insert_index:].lstrip()\n",
    "    else:\n",
    "        # 마침표가 없는 경우 전체 앞에 define 추가\n",
    "        result = define + \"\\n\" + question_text\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    i['conversations'][0]['value'] = insert_define_after_first_sentence(i['conversations'][0]['value'], define)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0]['conversations'][0]['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 저장\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_add_define.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)  # ensure_ascii=False to keep Korean characters intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few shot 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# \"/workspace/7.Error/error_full_list_final.json\" 읽기\n",
    "\n",
    "with open(\"/workspace/7.Error/error_full_list_final_new.json\", \"r\") as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['conversations'][0]['level'], data[0]['conversations'][0]['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD\n",
    "\n",
    "Classification_Omission = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: '0'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe.'\n",
    "Answer: '1'\n",
    "'''\n",
    "Classification_Insertion = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: '0'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung. Pleural effusions in the form of minimal thin smears are observed in both hemithorax.'\n",
    "Answer: '1'\n",
    "'''\n",
    "Classification_Direction = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: '0'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the left lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: '1'\n",
    "'''\n",
    "Classification_Size = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: '0'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 1.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: '1'\n",
    "'''\n",
    "Classification_Unit = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: '0'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 mm is observed in the right lower lung.'\n",
    "Answer: '1'\n",
    "'''\n",
    "Classification_Typo = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: '0'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchya window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: '1'\n",
    "'''\n",
    "\n",
    "Detection_Insertion = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'No errors detected.'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung. Pleural effusions in the form of minimal thin smears are observed in both hemithorax.'\n",
    "Answer: 'Error: Pleural effusions in the form of minimal thin smears are observed in both hemithorax.'\n",
    "'''\n",
    "Detection_Direction = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'No errors detected.'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the left lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'Error: A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the left lung upper lobe.'\n",
    "'''\n",
    "Detection_Size = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'No errors detected.'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 1.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'Error: A few nonspecific nodules measuring 1.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe.'\n",
    "'''\n",
    "Detection_Unit = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'No errors detected.'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 mm is observed in the right lower lung.'\n",
    "Answer: 'Error: In the examination made in the lung parenchyma window; A mass measuring 3 mm is observed in the right lower lung.'\n",
    "'''\n",
    "Detection_Typo = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'No errors detected.'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchya window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'Error: In the examination made in the lung parenchya window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "'''\n",
    "\n",
    "\n",
    "Correction_Omission = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'No errors detected.'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe.'\n",
    "Answer: 'Corrected: In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "'''\n",
    "Correction_Direction = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'No errors detected.'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the left lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'Corrected: A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe.'\n",
    "'''\n",
    "Correction_Size = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'No errors detected.'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 1.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'Corrected: A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe.'\n",
    "'''\n",
    "Correction_Unit = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'No errors detected.'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 mm is observed in the right lower lung.'\n",
    "Answer: 'Corrected: In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "'''\n",
    "Correction_Typo = '''\n",
    "<Example #1>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'No errors detected.'\n",
    "<Example #2>\n",
    "Report: 'In both lungs, there is a mosaic attenuation pattern more evident in the lower lobes. Sequela parenchymal changes are observed in the left lung upper lobe lingular segment, bilateral lung lower lobe posterobasal segment and right lung middle lobe medial segment. A few nonspecific nodules measuring 5.5 mm in size are observed in the posterior and anterior segment of the right lung upper lobe. In the examination made in the lung parenchya window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "Answer: 'Corrected:  In the examination made in the lung parenchyma window; A mass measuring 3 cm is observed in the right lower lung.'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.load(\"/workspace/2.Multi_Modal/M3D/Data/data/M3D-Seg/M3D_Seg/0006/case_00168/image.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.360952, -1.5798162, -7.643021e-05, 0.9998113)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max(), a.min(), a.mean(), a.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
